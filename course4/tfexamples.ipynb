{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kaggletitanic.png\">\n",
    "\n",
    "train.csv renamed to train_kaggletitanic.csv\n",
    "test.csv renamed to test_kaggletitanic.csv\n",
    "gender_submission.csv renamed to kggletitanic_gendersubmission.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pandasaxis.jpg\">\n",
    "To drop columns specify axis=1, to drop 0 axis=0. Same with numpy. Axis 0 is row 1 is column. \n",
    "<img src=\"numpyaxis.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "import tensorflow as tf    # Of course, we need TensorFlow.\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train = pd.read_csv('train_kaggletitanic.csv')\n",
    "df_train.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "df_train=df_train.drop(['PassengerId','Name','Ticket', 'Cabin'],axis=1)\n",
    "df_train['Sex'] = df_train['Sex'].map({'female':0, 'male':1}).astype(int) \n",
    "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_train = df_train.drop('Embarked', axis=1)\n",
    "age_mean = df_train['Age'].mean()\n",
    "age_std = df_train['Age'].std()\n",
    "df_train['Age'] = (df_train['Age'] - age_mean) / age_std\n",
    "\n",
    "fare_mean = df_train['Fare'].mean()\n",
    "fare_std = df_train['Fare'].std()\n",
    "df_train['Fare'] = (df_train['Fare'] - fare_mean) / fare_std\n",
    "print(\"Number of missing 'Age' values: {:d}\".format(df_train['Age'].isnull().sum()))\n",
    "\n",
    "# A simple method to handle these missing values is to replace them by the mean age.\n",
    "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].mean())\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Survived', axis=1).as_matrix()\n",
    "y_train = df_train['Survived'].as_matrix()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure dims match\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "labels_train = (np.arange(2) == y_train[:,None]).astype(np.float32)\n",
    "labels_test = (np.arange(2) == y_test[:,None]).astype(np.float32)\n",
    "print(labels_train.shape,labels_test.shape)\n",
    "print(X_train[0:4])\n",
    "print(labels_train[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=(None, X_train.shape[1]), name='inputs')\n",
    "label = tf.placeholder(tf.float32, shape=(None, 2), name='labels')\n",
    "\n",
    "# First layer\n",
    "hid1_size = 128\n",
    "w1 = tf.Variable(tf.random_normal([hid1_size, X_train.shape[1]], stddev=0.01), name='w1')\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=(hid1_size, 1)), name='b1')\n",
    "y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1)), keep_prob=0.5)\n",
    "\n",
    "# Second layer\n",
    "hid2_size = 256\n",
    "w2 = tf.Variable(tf.random_normal([hid2_size, hid1_size], stddev=0.01), name='w2')\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=(hid2_size, 1)), name='b2')\n",
    "y2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w2, y1), b2)), keep_prob=0.5)\n",
    "\n",
    "# Output layer\n",
    "wo = tf.Variable(tf.random_normal([2, hid2_size], stddev=0.01), name='wo')\n",
    "bo = tf.Variable(tf.random_normal([2, 1]), name='bo')\n",
    "yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo))\n",
    "\n",
    "# Loss function and optimizer\n",
    "lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "\n",
    "# Prediction\n",
    "pred = tf.nn.softmax(yo)\n",
    "pred_label = tf.argmax(pred, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operation which will initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Configure GPU not to use all memory\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Start a new tensorflow session and initialize variables\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another \n",
    "# 50 epochs with a smaller learning rate of 0.01\n",
    "for learning_rate in [0.05, 0.01]:\n",
    "    for epoch in range(50):\n",
    "        avg_cost = 0.0\n",
    "\n",
    "        # For each epoch, we go through all the samples we have.\n",
    "        for i in range(X_train.shape[0]):\n",
    "            # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={lr:learning_rate, \n",
    "                                                          inputs: X_train[i, None],\n",
    "                                                          label: labels_train[i, None]})\n",
    "            avg_cost += c\n",
    "        avg_cost /= X_train.shape[0]    \n",
    "\n",
    "        # Print the cost in this epcho to the console.\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy.eval(feed_dict={inputs: X_train, label: labels_train})\n",
    "print(\"Train accuracy: {:3.2f}%\".format(acc_train*100.0))\n",
    "\n",
    "acc_test = accuracy.eval(feed_dict={inputs: X_test, label: labels_test})\n",
    "print(\"Test accuracy:  {:3.2f}%\".format(acc_test*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_kaggletitanic.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all pre-processing steps as above\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_test['Sex'] = df_test['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')], axis=1)\n",
    "df_test = df_test.drop('Embarked', axis=1)\n",
    "df_test['Age'] = (df_test['Age'] - age_mean) / age_std\n",
    "df_test['Fare'] = (df_test['Fare'] - fare_mean) / fare_std\n",
    "df_test.head()\n",
    "X_test = df_test.drop('PassengerId', axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "for i in range(X_test.shape[0]):\n",
    "    df_test.loc[i, 'Survived'] = sess.run(pred_label, feed_dict={inputs: X_test[i, None]}).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = df_test['PassengerId']\n",
    "output['Survived'] = df_test['Survived'].astype(int)\n",
    "output.to_csv('prediction.csv', index=False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def param_size():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(f\"procsessing var:{variable} with shape:{shape}\")\n",
    "        print(f\"shape vars:{shape}, len shape:{len(shape)}\")\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            print(f\"processing dim:{dim}\")\n",
    "            variable_parameters *= dim.value\n",
    "        print(f\"adding var params:{variable_parameters}\")\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d2469b5d7c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1)), keep_prob=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mparam_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'param_size' is not defined"
     ]
    }
   ],
   "source": [
    "#how many parameters for a FC w/300x300 image input and 100 hidden units? First flatten the image\n",
    "#this can be misleading because these parameters dont include the learning rate\n",
    "tf.reset_default_graph()\n",
    "X_train=np.zeros((300*300,1))\n",
    "inputs = tf.placeholder(tf.float32, shape=(None, X_train.shape[0]), name='inputs')\n",
    "#label = tf.placeholder(tf.float32, shape=(None, 2), name='labels')\n",
    "\n",
    "# First layer\n",
    "hid1_size = 100\n",
    "w1 = tf.Variable(tf.random_normal([hid1_size, X_train.shape[0]], stddev=0.01), name='w1')\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=(hid1_size, 1)), name='b1')\n",
    "\n",
    "z1 = tf.add(tf.matmul(w1,tf.transpose(inputs)),b1)\n",
    "a1 = tf.nn.relu(z1)\n",
    "y1 = tf.nn.dropout(a1,keep_prob=0.5)\n",
    "#y1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1)), keep_prob=0.5)\n",
    "param_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 3 and 5 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,300,300,3], [5,5,5,5].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 3 and 5 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,300,300,3], [5,5,5,5].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3e8d3ddffa70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mparam_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    958\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3272\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1790\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs230/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 3 and 5 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,300,300,3], [5,5,5,5]."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X_train=np.zeros((300*300,1))\n",
    "inputs = tf.placeholder(tf.float32, shape=(None, 300,300,3), name='inputs')\n",
    "filter = tf.Variable(tf.random_normal([5,5,5,5]))\n",
    "strides=[1,1,1,1]\n",
    "padding=\"SAME\"\n",
    "tf.nn.conv2d(inputs,filter,strides,padding)\n",
    "param_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procsessing var:<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32_ref> with shape:(3, 3, 1, 32)\n",
      "shape vars:(3, 3, 1, 32), len shape:4\n",
      "processing dim:3\n",
      "processing dim:3\n",
      "processing dim:1\n",
      "processing dim:32\n",
      "adding var params:288\n",
      "procsessing var:<tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32_ref> with shape:(32,)\n",
      "shape vars:(32,), len shape:1\n",
      "processing dim:32\n",
      "adding var params:32\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "#train_data = mnist.train.images # Returns np.array\n",
    "#train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "#eval_data = mnist.test.images # Returns np.array\n",
    "#eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "test = np.arange(784)\n",
    "test = test.reshape(28,28)\n",
    "b =tf.convert_to_tensor(test,dtype=tf.float32)\n",
    "input_layer = tf.reshape(b, [-1, 28, 28, 1])\n",
    "\n",
    "# Convolutional Layer #1 bc there are 32 filters!!!!!\n",
    "conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu)\n",
    "param_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procsessing var:<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 1) dtype=float32_ref> with shape:(3, 3, 1, 1)\n",
      "shape vars:(3, 3, 1, 1), len shape:4\n",
      "processing dim:3\n",
      "processing dim:3\n",
      "processing dim:1\n",
      "processing dim:1\n",
      "adding var params:9\n",
      "procsessing var:<tf.Variable 'conv2d/bias:0' shape=(1,) dtype=float32_ref> with shape:(1,)\n",
      "shape vars:(1,), len shape:1\n",
      "processing dim:1\n",
      "adding var params:1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "test = np.arange(36)\n",
    "test = test.reshape(6,6)\n",
    "b =tf.convert_to_tensor(test,dtype=tf.float32)\n",
    "input_layer = tf.reshape(b, [-1, 6, 6, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=1,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"valid\",\n",
    "      activation=tf.nn.relu)\n",
    "param_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(x_train.shape, y_train.shape, x_test.shape,y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=(100,28))\n",
    "labels_placeholder = tf.placeholder(tf.int32, shape=(100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

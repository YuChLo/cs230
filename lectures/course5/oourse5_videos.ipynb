{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Why Sequence Models</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Notation</h6>\n",
    "$x^{(j)[i]<j>}$ square brackets are layers,angle brackets are words parenthesis are training examples. For inputting word into RNN cells in parallel. General notation\n",
    "is t for temporal notation: $x^{<t>}$. $T_x=9$ where Tx is input length 9 words input and Ty=3 where Ty is output word length\n",
    "    Input and output lengths can be different.\n",
    "<img src=\"not1.png\">\n",
    "How to represent words in a sentence? Build a vector of dictionary of words and match a word to an integer index. a is index 1, potter is 6830. \n",
    "A word is a onehot vector where the position of the one hot is the index in the dict. Goal is to learn a mapping\n",
    "using a sequence to a target label y. DO this as a supervised learnign problem. What if you encounter word not\n",
    "in vocab? Use UNK token and add in dicttionary. \n",
    "<img src=\"not2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>RNN Model</h6>\n",
    "You can use a FFN but this doesnt work well because the input lengths and output lengths are variable. \n",
    "If every sentence had a max len we could pad but this wastes space. A naive FNN doesnt share featrues across text hten \n",
    "harry in position 1 then would be good if it figures harry in another position can be name if first seeing it in position\n",
    "1 it knows it is a name and it can abstract this up to higher layers. We saw this in convnets wheree deeper layers produced\n",
    "higher layers of abstraction. \n",
    "<img src=\"rnn1.png\">\n",
    "What ia a RNN? The activateion value in timestep 1 is passed along to timestep2. INput X, output y and shared parameters\n",
    "Wzx, Wya, Wau. Making prediction for y3 it gest information from x3 as well as x2 and x1. Weakness of RNN is it only uses\n",
    "inforamtion from earlier in network not info from later words w4, s5, w6. Example sentence is you see president later\n",
    "in sentence. Give teh first 3 words not possible to know the word teddy is part if name. Weakness of RNN!!!Will talk about\n",
    "bidirectional BRNNs which fix this problem. \n",
    "<img src=\"rnn2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>RNN model</h6>\n",
    "Forward prop $a^{<1>} = g(W_{aa}^a{<0>} + W_{ax}z*{<1>} +b_{a})$ and the output $\\hat{y}^{<1>}=g(W_{ya}a^{<1>} + b_y)$\n",
    "Use tanh and reLU have other ways of preventing vanishing gradient problem. If binary classification use sigmoid activation\n",
    "if k-class use softmax. FOr the NER task teh second g can be sigmoid. at time t, $a^{<t>} = g(W_{aa}a^<t-1> + W_{ax}x^{<t>} + b_a)$\n",
    "and the output is: $\\hat{y}^{<t>} = W_{ya}a^{<t>}+b_y$\n",
    "    <p></p>Initialize $a^{<0>}$ to all zeros. \n",
    "<img src=\"fprnn1.png\">\n",
    "Rewrite the equations into matrix form. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>RBPTT</h6>\n",
    "Parameters $W_{a}$ and $b_a$ are shared in each time step. Output $\\hat y^{[1]}$ and ti compute y hat you need $W_y$ and $b_y$\n",
    "to compute bp you need a loss function. Define this as the standard logistic loss or standard CE loss. This loss is the standrad loss for a\n",
    "single prediction or single time step. Same as logistic or binary classification loss. \n",
    "$L^{<t>}(\\hat y^{<t>},y^{<t>})= -y^{<t>}log(\\hat y^{<t>})-(1-y^{<t>})log(1- \\hat y^{<t>})$ The loss for the whole sequence is \n",
    "$L=\\sum(L^{<t>}(\\hat y^{<t>},y^{<t>}))$ This is the computation graph. the most significant recursive calculation is the one that\n",
    "goes from left to right. forward prop you are scanning from left to right and in bptt you are reversing the sequence. \n",
    "<img src=\"bptt1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Different types of RNNS</h6>\n",
    "before we only saw RNNS with input sequence length equal to output sequence length or where Tx=Ty. \n",
    "We see different arch where Tx!=Ty. In sentiment classification input is sequence and output is 0/1 of length 1. \n",
    "In machine translation an input sequence can be different than output sequence lengths. modify architectures based\n",
    "on unreasonable effectiveness of xxx networks. Many to many architecture: input has many inputs(sequence) and output \n",
    "    sequence has many outputs like in machine translation. Many to one: input many, output is 0/1 like in sentiment classifcaiton.         \n",
    "<img src=\"diff_rnn1.png\">\n",
    "Another any to many architecture: NN read in the french sentence then have NN output tranlation. Tx and Ty are different\n",
    "    lengths. 2 distinct parts, an encoder and a decoder. this is different than the many to many in the slide above which \n",
    "    isnt an encoder/decoder\n",
    "<img src=\"diff_rnn2.png\">\n",
    "summary, one to one: , one to many: one input to many output, image input output caption; many to one: sentiment classification, \n",
    "            many to many: machine translation, many to many: encoder/decoder vs. rnn. \n",
    "<img src=\"diff_rnn3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Language model and sequence generation</h6>\n",
    "Build LM using RNN. The difference between 2 sentences \"the apple and pair salad\" or \"the apple and pear salad\" the\n",
    "language models picks the second sentence as being the correct sentecne. the LM gives you P(sentence)=?. \n",
    "\n",
    "<img src=\"lm1.png\">\n",
    "How to build a LM? Training set = corpus of text which you tokenize into dictionary then index teh words and represent\n",
    "words as 1 hot vectors w/len vectors = length of dictionary or number of unique words. If you dont see w word in vocab\n",
    "add a token=UNK and add EOS for period. So len(dict)+2. Next build an RNN to model sequence probability of sentences. \n",
    "<img src=\"lm2.png\">\n",
    "at time=0 you computes some activation of the first word or $x^<1>$ the softmax a1 will calculcate probability of any\n",
    "word in the dictionary if we set x to 0. and previous state to 0. yhat is softmax output. if you have 10k word vocabulary\n",
    "then 10k way softmax. then to next step soem activate a1, predict the second word having seen the first word cat. \n",
    "What is the prob of cats p(a) P(cats), for y<1>. For the second stage, P(second word| cats), we saw cats first so\n",
    "the sequennce y<1>=x<2) so yhat<2> is average, p(average|cats). the output of a3 before the softmax and after the softmax\n",
    "we get yhat<3> whih is p(15| cats average) all way to end. The loss function is SUM of softmax loss for each stage\n",
    "<img src=\"lm3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>samlling novel sequences</h6>\n",
    "After training rnn you can sample a sequence from this distribution to generate a novel sequence. Input x<1> and a<0>\n",
    "are 0 then sample from softmax and then take vector numpy.random.choice() to sampe according to the softmax distributio nin a<1>!!\n",
    "Then to the second timestemp needs y<1> input so feed in the one you picked into input of next stage!!\n",
    "If first word is The then put The into second stage and you figure out P(?|The) and turns out you run numpy.randon.choice\n",
    "agiain ot get another word. Keep going till you get a EOS. That may take a long time. Or you can sample a fixed number of\n",
    "tokens. This procedure will sometimes generate a unk or unkown token. You can reject an unknown sample ans sample again. \n",
    "This is ok but just chained probability at word level RNN. Depend\n",
    "<img src=\"sample1.png\">\n",
    "Can build a character level RNN to make words/sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>vanishing gradients w/RNN</h6>\n",
    "<p>you see a sentence out of an RNN, teh cast whcih already ate a.. was full</p>\n",
    "<p>the cat which ate ...were already full</p>\n",
    "Basic RNN not good at training long term dependencies. The gradients cant propagate all way back. Foward goes from left \n",
    "to rgith and difficult fof later time steps to affect computations earlier. Difficult to get NN to recognize single or plural\n",
    "noun. THe basic RNN has local influences. The output yhat<3> is mainly influenced by values near 3. hard to get influence\n",
    "from far away. Tgus us weakness of basic RNN algorithm. Also talked abut exploding gradients. Vanishing is bigger problem\n",
    "although Explodign gradient can cause parameters to be so large the parametrs wont work will see NaN. Numerical overflow/ for\n",
    "VG you dnot see. Apply gradient clipping to fix exploding gradients. If bugger than threshold reset it. \n",
    "<img src=\"vangrad1.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>GRU</h6>\n",
    "GRU is fix for vanishing gradients adn better for long range connections. Formula for computing activation for t sequnce. \n",
    "\n",
    "<img src=\"gru1.png\">\n",
    "GRU has new unit memory cell which will remember whether the cat is singular or plural. At time t the $c^{<t>}$ will have \n",
    "some value and we set this to be the activation $c^{<t>}=a^{<t>}$. \n",
    "At every time step we are going to consider replacing ct with ctilde, where ctilde is:\n",
    "$\\tilde c^{<t>}=tanh(W_a[a^{<t-1>},x^{<t>}+b_a])$\n",
    "In the GRU the ct is equal to the output activation. Later they will be 2\n",
    "separate values. and  The gate will call $\\Gamma_u =\\sigma(W_u[c^{<t-1>},x^{<t>}]+b_u)$ gamma is an update gate is always either 0 or 1. \n",
    "Can think of c as being set to 0 or 1 if cat is singular or plural and gru will remember singular. Gamma determines when \n",
    "to update the c value. This is 1 bit to remember a dependency. The actual value of ct is gate times c....\n",
    "<img src=\"gru2.png\">\n",
    "because gamma can be close to 0 or a very small number which makes 1-gamma_u close to 1,  \n",
    "it can allow c<t-1> to be propagate back to c<t>. \n",
    "<img src=\"gru3.png\">\n",
    "<img src=\"gru4.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>LSTM</h6>\n",
    "<img src=\"1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Bidirectional RNN</h6>\n",
    "<img src=\"bidir1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Deep RNNS</h6>\n",
    "<img src=\"deeprnns1.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 Word representation</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 embeddings</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 properties of word embeddings </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 embedding matrix </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 learning word embeddings</h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 word2vec</h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<h6>week2 negative sampling</h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 glove </h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 sentiment</h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 debiasing word embeddings</h6>\n",
    "on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 basic models</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 picking most likely sentence</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 beam search</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 refinements to bs</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 error analyais bs</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 blue score</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 attention model intuition</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 attention model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 speech recognitoion</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week3 trigger word detection</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"c5w1q1_2.png\">\n",
    "<img src=\"c5w1q1_2pre.png\">\n",
    "<img src=\"c5w1q10.png\">\n",
    "<img src=\"c5w1q3_4.png\">\n",
    "<img src=\"c5w1q5_6.png\">\n",
    "<img src=\"c5w1q5_6pre.png\">\n",
    "<img src=\"c5w1q7.png\">\n",
    "<img src=\"c5w1q7_8pre.png\">\n",
    "<img src=\"c5w1q8.png\">\n",
    "<img src=\"c5w1q9.png\">\n",
    "<img src=\"c5w1q9_10pre.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"c5w2q10.png\">\n",
    "<img src=\"c5w2q1_2.png\">\n",
    "<img src=\"c5w2q1_2pre.png\">\n",
    "<img src=\"c5w2q3_5.png\">\n",
    "<img src=\"c5w2q3pre.png\">\n",
    "<img src=\"c5w2q4pre.png\">\n",
    "<img src=\"c5w2q5pre.png\">\n",
    "<img src=\"c5w2q6.png\">\n",
    "<img src=\"c5w2q6_7pre.png\">\n",
    "<img src=\"c5w2q7_9.png\">\n",
    "<img src=\"c5w2q8_10pre.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

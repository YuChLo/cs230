{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for practice only.. repeat the hw assignment on my own\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from testCases_v2 import *\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "#from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1) # set a seed so that the results are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)\n",
    "    \n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def load_planar_dataset():\n",
    "    np.random.seed(1)\n",
    "    m = 400 # number of examples\n",
    "    N = int(m/2) # number of points per class\n",
    "    D = 2 # dimensionality\n",
    "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
    "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
    "    a = 4 # maximum ray of the flower\n",
    "\n",
    "    for j in range(2):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
    "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        Y[ix] = j\n",
    "        \n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def load_extra_datasets():  \n",
    "    N = 200\n",
    "    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n",
    "    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n",
    "    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n",
    "    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n",
    "    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n",
    "    \n",
    "    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n",
    "\n",
    "#test_cases_v2.py\n",
    "import numpy as np\n",
    "\n",
    "def layer_sizes_test_case():\n",
    "    np.random.seed(1)\n",
    "    X_assess = np.random.randn(5, 3)\n",
    "    Y_assess = np.random.randn(2, 3)\n",
    "    return X_assess, Y_assess\n",
    "\n",
    "def initialize_parameters_test_case():\n",
    "    n_x, n_h, n_y = 2, 4, 1\n",
    "    return n_x, n_h, n_y\n",
    "\n",
    "\n",
    "def forward_propagation_test_case():\n",
    "    np.random.seed(1)\n",
    "    X_assess = np.random.randn(2, 3)\n",
    "    b1 = np.random.randn(4,1)\n",
    "    b2 = np.array([[ -1.3]])\n",
    "\n",
    "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
    "        [-0.02136196,  0.01640271],\n",
    "        [-0.01793436, -0.00841747],\n",
    "        [ 0.00502881, -0.01245288]]),\n",
    "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
    "     'b1': b1,\n",
    "     'b2': b2}\n",
    "\n",
    "    return X_assess, parameters\n",
    "\n",
    "def compute_cost_test_case():\n",
    "    np.random.seed(1)\n",
    "    Y_assess = (np.random.randn(1, 3) > 0)\n",
    "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
    "        [-0.02136196,  0.01640271],\n",
    "        [-0.01793436, -0.00841747],\n",
    "        [ 0.00502881, -0.01245288]]),\n",
    "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
    "     'b1': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    "     'b2': np.array([[ 0.]])}\n",
    "\n",
    "    a2 = (np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]))\n",
    "    \n",
    "    return a2, Y_assess, parameters\n",
    "\n",
    "def backward_propagation_test_case():\n",
    "    np.random.seed(1)\n",
    "    X_assess = np.random.randn(2, 3)\n",
    "    Y_assess = (np.random.randn(1, 3) > 0)\n",
    "    parameters = {'W1': np.array([[-0.00416758, -0.00056267],\n",
    "        [-0.02136196,  0.01640271],\n",
    "        [-0.01793436, -0.00841747],\n",
    "        [ 0.00502881, -0.01245288]]),\n",
    "     'W2': np.array([[-0.01057952, -0.00909008,  0.00551454,  0.02292208]]),\n",
    "     'b1': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    "     'b2': np.array([[ 0.]])}\n",
    "\n",
    "    cache = {'A1': np.array([[-0.00616578,  0.0020626 ,  0.00349619],\n",
    "         [-0.05225116,  0.02725659, -0.02646251],\n",
    "         [-0.02009721,  0.0036869 ,  0.02883756],\n",
    "         [ 0.02152675, -0.01385234,  0.02599885]]),\n",
    "  'A2': np.array([[ 0.5002307 ,  0.49985831,  0.50023963]]),\n",
    "  'Z1': np.array([[-0.00616586,  0.0020626 ,  0.0034962 ],\n",
    "         [-0.05229879,  0.02726335, -0.02646869],\n",
    "         [-0.02009991,  0.00368692,  0.02884556],\n",
    "         [ 0.02153007, -0.01385322,  0.02600471]]),\n",
    "  'Z2': np.array([[ 0.00092281, -0.00056678,  0.00095853]])}\n",
    "    return parameters, cache, X_assess, Y_assess\n",
    "\n",
    "def update_parameters_test_case():\n",
    "    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n",
    "        [-0.02311792,  0.03137121],\n",
    "        [-0.0169217 , -0.01752545],\n",
    "        [ 0.00935436, -0.05018221]]),\n",
    " 'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n",
    " 'b1': np.array([[ -8.97523455e-07],\n",
    "        [  8.15562092e-06],\n",
    "        [  6.04810633e-07],\n",
    "        [ -2.54560700e-06]]),\n",
    " 'b2': np.array([[  9.14954378e-05]])}\n",
    "\n",
    "    grads = {'dW1': np.array([[ 0.00023322, -0.00205423],\n",
    "        [ 0.00082222, -0.00700776],\n",
    "        [-0.00031831,  0.0028636 ],\n",
    "        [-0.00092857,  0.00809933]]),\n",
    " 'dW2': np.array([[ -1.75740039e-05,   3.70231337e-03,  -1.25683095e-03,\n",
    "          -2.55715317e-03]]),\n",
    " 'db1': np.array([[  1.05570087e-07],\n",
    "        [ -3.81814487e-06],\n",
    "        [ -1.90155145e-07],\n",
    "        [  5.46467802e-07]]),\n",
    " 'db2': np.array([[ -1.08923140e-05]])}\n",
    "    return parameters, grads\n",
    "\n",
    "def nn_model_test_case():\n",
    "    np.random.seed(1)\n",
    "    X_assess = np.random.randn(2, 3)\n",
    "    Y_assess = (np.random.randn(1, 3) > 0)\n",
    "    return X_assess, Y_assess\n",
    "\n",
    "def predict_test_case():\n",
    "    np.random.seed(1)\n",
    "    X_assess = np.random.randn(2, 3)\n",
    "    parameters = {'W1': np.array([[-0.00615039,  0.0169021 ],\n",
    "        [-0.02311792,  0.03137121],\n",
    "        [-0.0169217 , -0.01752545],\n",
    "        [ 0.00935436, -0.05018221]]),\n",
    "     'W2': np.array([[-0.0104319 , -0.04019007,  0.01607211,  0.04440255]]),\n",
    "     'b1': np.array([[ -8.97523455e-07],\n",
    "        [  8.15562092e-06],\n",
    "        [  6.04810633e-07],\n",
    "        [ -2.54560700e-06]]),\n",
    "     'b2': np.array([[  9.14954378e-05]])}\n",
    "    return parameters, X_assess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 400) (1, 400)\n",
      "[ 1.20444229  0.1587099   0.0952472   0.34917847  0.69415038  1.62065038\n",
      "  1.53856225  0.03630856  0.47459111  0.16569583  1.66446249  0.84028572\n",
      "  0.26169516  0.2316149   1.5801302   0.0063551   0.68061042  0.12140043\n",
      "  1.13281261  1.61505892  0.16645444  1.72438241  1.88667246  1.72327227\n",
      "  1.54661332  0.9845904   1.45313345  0.74904339  1.45048341  1.64287865\n",
      "  1.28141487  1.59574104  1.46298294  1.46629048  1.54348961  1.57013416\n",
      "  1.22995404  1.31142345 -1.99364553  0.39456475]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_planar_dataset()\n",
    "print(X.shape,Y.shape)\n",
    "#2,400\n",
    "#print first 10 columns or row 0. OK how o you know which ones are red or blue?\n",
    "print(X[0,0:40])\n",
    "print(Y[0,:])#well that is funky the first half is 0/red the second half is 1/blue\n",
    "print(X[1,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0]\n",
      "Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dc/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/dc/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegressionCV();\n",
    "clf.fit(X.T, Y.T);\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print(LR_predictions)\n",
    "\n",
    "print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(percentage of correctly labelled datapoints)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Neural Network model\n",
    "\n",
    "Logistic regression did not work well on the \"flower dataset\". You are going to train a Neural Network with a single hidden layer.\n",
    "\n",
    "**Here is our model**:\n",
    "<img src=\"classification_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "**Mathematically**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n",
    "\n",
    "Given the predictions on all the examples, you can also compute the cost $J$ as follows: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
    "\n",
    "**Reminder**: The general methodology to build a Neural Network is to:\n",
    "    1. Define the neural network structure ( # of input units,  # of hidden units, etc). \n",
    "    2. Initialize the model's parameters\n",
    "    3. Loop:\n",
    "        - Implement forward propagation\n",
    "        - Compute loss\n",
    "        - Implement backward propagation to get the gradients\n",
    "        - Update parameters (gradient descent)\n",
    "\n",
    "You often build helper functions to compute steps 1-3 and then merge them into one function we call `nn_model()`. Once you've built `nn_model()` and learnt the right parameters, you can make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 400) (1, 400)\n",
      "(2, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "#helper functions for FFNN. \n",
    "def get_dims(X,Y,num_hidden=4):\n",
    "    \"\"\"\n",
    "    X: input or training data. X formatte to input_size(number of input neurons), number of examples\n",
    "    Y: output labels formatted to output size(number of output neurons) and number of examples\n",
    "    NOTE: there is no test/train split\n",
    "    the input is a column of dimension n_x\n",
    "    \"\"\"\n",
    "    print(X.shape,Y.shape)\n",
    "    n_x = X.shape[0]\n",
    "    n_h = num_hidden\n",
    "    n_y = Y.shape[0]\n",
    "    return n_x,n_h,n_y\n",
    "\n",
    "print(get_dims(X,Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (2, 3)\n",
      "The size of the input layer is: n_x = 5\n",
      "The size of the hidden layer is: n_h = 4\n",
      "The size of the output layer is: n_y = 2\n"
     ]
    }
   ],
   "source": [
    "#change funnction layer_sizes to get_dims. \n",
    "X_assess, Y_assess = layer_sizes_test_case()\n",
    "(n_x, n_h, n_y) = get_dims(X_assess, Y_assess)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    \"\"\"\n",
    "    returns dict with W1,b1,W2,b2\n",
    "    \"\"\"\n",
    "    W1=np.zeros((n_x,n_h))\n",
    "    b1=np.zeros((1,n_h))\n",
    "    W2=np.zeros((n_h,n_y))\n",
    "    b1=np.zeros((1,n_y))\n",
    "    \n",
    "    parameters={\"W1\":W1,\"b1\":b1,\"W2\":W2,\"b2\":b2}\n",
    "    return parameters\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

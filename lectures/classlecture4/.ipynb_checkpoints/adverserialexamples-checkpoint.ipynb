{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>adverserial examples</h6>\n",
    "In the Goodfellow paper says linear networks and high dimensionality cause small perturbations to be classified as \n",
    "mistakes. If you have a CNN cat classifier it is possible to create an image that looks like a blurry cat\n",
    "that is classified as 99% iguana. It clearly isnt an iguana. Or you can create\n",
    "a random noise image that is classified as a cat or iguana. The fact that this is defined by a small perturbation we\n",
    "can use the NN and bp to find these adverserial examples which cause the network to fail!!\n",
    "<img src=\"adv1.png\">\n",
    "We want to use the network and our tools to find these adverserial examples. what is a loss function to find an image that\n",
    "will be classified as an iguana. Loss function MSE L2 loss. THen the process is same as neural style transfer. \n",
    "$L(\\hat y, y) = \\frac{1}{2} \\mid \\mid (\\hat y(W,x,b)-y_{iguana})\\mid \\mid ^2$. L2 norm.  \n",
    "We can start with random noise as X and iterate till we get an imsage with a small loss so it looks like an iguana. We\n",
    "have the dW and dB for L2 loss. \n",
    "<img src=\"adv2.png\">\n",
    "How do we get an image to look like a cat? Modify the loss funcion to include y-ycat\n",
    "$L(\\hat y, y) = \\frac{1}{2} \\mid \\mid (\\hat y(W,x,b)-y_{iguana})\\mid \\mid ^2 + L(\\hat y,y_{cat})$.\n",
    "the loss between teh cat and outptu image is lambda*L2 loss(image,cat); should be predicted and cat\n",
    "$\\lambda \\mid \\mid x  - x_{cat} \\mid \\mid^2)$ is x wrong? \n",
    "\n",
    "<img src=\"adv3.png\">\n",
    "what should x be? best would be cat in the loss function. Looks like x is correct then. Verify vs. adverserial_examples.ipynb\n",
    "<img src=\"adv4.png\">\n",
    "Never covered teh signed gradient method: \n",
    "<img src=\"adv5.png\">\n",
    "types of attacks. nontargetd and targeted attacks. 2 different types of attacks \n",
    "Knowledge of attacker, if attacker has access to network, white box ix easier to attack. Like having source code. \n",
    "Black box dont have access to network. how to attack? if you can only query once? more complicated. complex property\n",
    "of networks is transferrable. I can build my own classifier. Defenses to defend. 1)Create a safety net. 2) generate adverserial examples and train on these. very costly\n",
    "3) modify loss function, train on normal examples and train on adverserial examples. what is the complexity of 3? For each\n",
    "iteration of gradient descent then you have to do a separate round trip for the adverserial loss. Also another called logit \n",
    "training. Why are NN vulernable to adverserial examples? Why do adveserial examples exist? Argue the linear part of NN. \n",
    "Start w linear regression. Forward propagation is; g=Wx+b. use a 6 ddimensional input. Use a neuron w/no activation because\n",
    "linear regression. use L1 or L2 loss to train the network. X is a column vector of 6 ross.  then w has to be a row vector of 6 cols. \n",
    "w=[1,3,-1,2,2,3], b=0. x=[1,-1,2,0,3,-1].T sp y=wx+b we have y=1-3-2+0+6-6=-4.\n",
    "How to change x into x* so yhat changes radically but x and x* is close? Lets look at the derivative $\\frac{\\partial \\hat y}{\\partial x}=w^T$ but what the shape of x? \n",
    "a derivative of a scaler w with respect to a vector x is a vector.. so w becmmes wT\n",
    "<img src=\"adv6.png\">\n",
    "if we calculate $x^*=x+\\epsilonw^T $ A\n",
    "<img src=\"adv6a.png\">\n",
    "Math error\n",
    "<img src=\"adv6b.png\">\n",
    "<img src=\"adv7.png\">\n",
    "a small epsilon of 0.2 pushed yhat from -4 all teh way to 0.5. \n",
    "<img src=\"adv8.png\">\n",
    "IF W is large then x* is not similar to x. if one entry if W is large then xi is different than x%. \n",
    "so what we are going to do we are going to take sign of W so if positive then we know we push more postivei. And\n",
    "if we did - epsilon above this is negative so it pushs more megative is epsilon is negative. As x grows in dimension\n",
    "then the effect of epsilon increases. Even if we keep epsilon super super super small it doesnt mateter because\n",
    "we get teh term y=Wx has a lot more terms which we have to add up. So taht number gross. You look at both if you have large \n",
    "number in W and you look at number of dimensions in x, x is small cause you normalised it but the dimension of x is big. \n",
    "So you get large impact and yhat is far away from y. Bad news. Anotehr curse of dimensionality. \n",
    "<img src=\"adv9.png\">\n",
    "fast way to generate adverserial examples. fast gradient sign metnhod from paper. We are pushing the pixels in\n",
    "one direction. All of tehse are linear because we want fast training. We put sigmoid in linear region because\n",
    "we want fast training. \n",
    "<img src=\"adv10.png\">\n",
    "Fully connected network using chain rule on x gives  \n",
    "<img src=\"adv11.png\">\n",
    "<img src=\"adv12.png\">\n",
    "<img src=\"gan1.png\">\n",
    "<img src=\"gan2.png\">\n",
    "There are 2 distribuitons teh first is of some real world data of objects and the second is we have a generative\n",
    "model generating objects we want to match the 2 distribuitons together to get the generative network to make\n",
    "real world data. \n",
    "<img src=\"gan3.png\">\n",
    "We want to train the generator, Input random data, and right now it outputs random image. No labelled data. We are going\n",
    "to train w/Discrimiator. \n",
    "<img src=\"gan4.png\">\n",
    "input to discrimimator is a binary classifer output 1 if image real, 0 if generated. x comes from generated \n",
    "image. If the image comes form our database we want the discriminator to be 1. \n",
    "we backprop usign BCE to train the discriminator. We are going to direct gradient back to the generator. We can \n",
    "back prop all way back to generator. Mixing minibatch one for real data and one for fake data. \n",
    "<img src=\"gan5.png\">\n",
    "what shold be the cost for the discriminator assuming 2 minibatches, one from G and one from database. 2 terms. Binary\n",
    "cross entropy. we have 2 labels, yreal and ygenerated. We know yreal=1 and ygen=0. \n",
    "<img src=\"gan6.png\">\n",
    "<img src=\"gan7.png\">\n",
    "<img src=\"gan8.png\">\n",
    "<img src=\"gan9.png\">\n",
    "<img src=\"gan5.png\">\n",
    "<img src=\"gan5.png\">\n",
    "<img src=\"gan5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Why ML Strategy</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3M1.pdf\t      mls1a.png  mls2b.png  mlstrat1.png  mlstrat4.png\r\n",
      "C3M2.pdf\t      mls1b.png  mls3a.png  mlstrat2.png  mlstrat.ipynb\r\n",
      "course3_videos.ipynb  mls2a.png  mls3b.png  mlstrat3.png  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>single number evaluation</h6>\n",
    "Use a single number evaluation metric which at first is dev set error on algoritmns. You can \n",
    "pick something like precision/recall. What percantage are cats? for classifier A which says 95% is a cat. Recall\n",
    "asys which percentage of actual cats are correctly reognized? \n",
    "Usually tradeoff between precision and recall. PRoblem is if classifier A does better on reacall but B does better\n",
    "on precision you arent sure which one is better. If you have 5 classifiers traiking, you want to pick 1/10 or one to \n",
    "focus on. Rather than using 2 numbers use 1 number which combines the 2. F1 score combines these 2. Aerage of presisiopn\n",
    "p and recall r. F1=2/(1/p + 1/r) this is called the harmonic mean of the 2 numbers. Not an arithmetic mean. Has\n",
    "some advantages over arithmetic mean. Having a well defined dev set plus a single number evaluation metric allows you\n",
    "to tell which classifier is better. \n",
    "<img src=\"mls1a.png\">\n",
    "One strategy is to pick teh average. \n",
    "<img src=\"mls1b.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Precision and Recall</h6>\n",
    "Where are false postitives measured? \n",
    "Where are false negatives measured? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>precision recall f1 questions</h6>\n",
    "(2 points) You are building a model to predict the presence (labeled 1) or absence (labeled 0) of a tumor in a brain scan. \n",
    "The goal is to ultimately deploy the model to help doctors in hospitals. Which of these two metrics would you choose to use?\n",
    "\n",
    "<p></p>\n",
    "(i) Precision = True positive examples/Total predicted positive examples\n",
    "<p></p>\n",
    "(ii) Recall =True positive examples/Total positive examples.\n",
    "THis is the same problem as porn in teh cat example? We get some image which is not a tumor but is something else. \n",
    "What is F1? \n",
    "If you are building a trigger word system what is metric? F1, precision, recall? \n",
    "If we use precision we get 90% on training example accuracy. \n",
    "if we use recall we get false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>satisficing and optimizing</h6>\n",
    "2 examples one is where have 2 metrics accuracy and running time we can define a formula cost = accuracy - 0.5*runningtime\n",
    "which is a single number. The problem is this seems a bit artificial.\n",
    "one solution to this is we can say twe want to maximize the accuracy but we have to satisfy the condition \n",
    "teh running time is < 100ms. Running time is a satisficing metric and accuracy\n",
    "is an optimzing metric. This is one way to combine 2 metrics and have 1 number to pick the best\n",
    "classifier which is classifier B cause it has teh beat accuracy which satifices the N-1 metrics. \n",
    "For N metrics we optimize 1 and make N-1 satisfiicig. \n",
    "<img src=\"mls2a.png\">\n",
    "Here is another example of a trigger word. hi hao baidu. Care about accuracy of trigger word also care about \n",
    "false positives maybe one way to combine accuracy subject to at most 1 falst positve 24hrs of operation. Accuracy\n",
    "is the optimizing metric and #of falst positives is satisficing metric. \n",
    "If yuo train vs. dev set error then your error maybe underfit because the test set is in 4 other regions and you \n",
    "tested on a dev set with a different distribution. \n",
    "\n",
    "<img src=\"mls2b.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>train/dev/test distributions</h6>\n",
    "IN ML try all ideas w/traing set and pick errors on dev set. Than take 1 classifier happy with. If operating in tehe \n",
    "international regions. How do you set up dev and test set? You can pick 4 regions randomly for dev and another 4 for test\n",
    "this is a very bad idea bc test and dev set come from different distributions. Make sure you have dev and test set\n",
    "from same distribution. To avoid this take all this data and randomly shuffle/split. \n",
    "<img src=\"mls3a.png\">\n",
    "If test and dev from different distributions he shows 2 different targets in the picture. This is high variance. \n",
    "You can take test and dev set data combine/shuffle/split\n",
    "<img src=\"mls3b.png\">\n",
    "Given input X can you predict loan application. Dev set came from medium income zip codes. Team dcided to test on \n",
    "low income zipcodes. The distirbution was different and the classifier didnt work well. wasted 3 months of time. \n",
    "Team spent 3 months aiming for 1 target and couldnt hit other target. Chose dev/test set and reflects same distribution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>size of dev and test sets</h6>\n",
    "old rules were train/test 70/30 or train/dev/test 60/20/20. For smaller data sets this was reasonable if had 1k examples or\n",
    "10k examples. But now have 1m dataset, heed onlhy 10k for test/dev. 98 percent in train and 1 percent is 10k. \n",
    "If 10k examples give enough confidence in performance, sometimes dont need dev set just train/dev set. All uou care\n",
    "about is train data and dev set no test set. This gives an unbiased estimate of training error if you have separate\n",
    "dev test set. You can overfit the dev set if you dont have a separate test set. Era of big data the classic split\n",
    "no longer holds. \n",
    "<img src=\"mls4a.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>when to change dev/test sets and metrics</h6>\n",
    "Sometimes you realise target is incorrect. You see algo A has lower error but has porn. In cntrast b has higher\n",
    "error but B is better. SO what happened? A is better on metric but is worse bc the metric is not accurate. To \n",
    "modify teh error metric add a weight term which gets set to a large number when you detect porn. Because it \n",
    "is only detected as a misclassification it is not enough. Some kinds of misclassificaitons even though the \n",
    "error rate is lower are worse. \n",
    "<img src=\"mls5a.png\">\n",
    "If you want the normalization constant to be right chagne from 1/m to sum of wi so the error is still between 0 and 1???\n",
    "\n",
    "Verify this....\n",
    "<img src=\"mls5b.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>why human level performance</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>avoidable bias</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>understanding human level performance</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>surpassing human level performance</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>improving model performacne</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 carrying out error analysis</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 cleaning up incorretly labeled data</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 build your first system quickly</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 training and testing on different</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 bias and variance w/mismatched data distributions</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 addressing data mismatch</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 transfer learning</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 multitask learning</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 what is end to end dl?</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>week2 whether to use end to end</h6>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

2 layer network practice numbers 
course1:
practice loss functions, how to compose them binary classification, multinomial classification, transfer styling
practice activation functions, relu, linear, tanh, sigmoid given 2 values what it would look like
practice derivative bp w/different activation functions



course2: optimizatin, 
bias and variance, how to reduce w/early stopping, dropout, regularization, 
math expression for regularization L1 and L2, math expression for dropout, 
GANS: lecture only, practice activation functions, how architecture works


Lectures
1: 
2:

Disussion Sectoin
week1:
week2: backprop of linear network, 
week3: YOLO iguana bounding box exercise.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>learing word embeddings</h6>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>learing word embeddings</h6>\n",
    "building a neural language model is a way to build embeddings. COnvert a sentence to vocab/index. Take a list of words\n",
    "and starting w first word I, from \"I want a glass of orange ....\" we want to convert words to one hot vectors. Then when \n",
    "we multiply the onehot w/an embedding we get the onehot*embedding to get embedding vector for each word. \n",
    "Each embedding\n",
    "is 300 long and feed each on into a a NN and into softmax and classifies among 10k outputs which one is the most likely. J\n",
    "Predict juice. The hidden layer is $W^{[1]}, b^{[1]}$ and the softmax is $W^{[2]}, b^{[2]}$. We stack 6 embedding\n",
    "vectors together to get 1800. Or have window always look at previous 4 words and you get rid of the first 2 so NN inputs\n",
    "1200 dim is input vector. Teh parameters of model is matrix E then weights/biases are also parameteres. Use bp to preform \n",
    "next word in text corups. This will learn word embeddigns. There is an incentive to make apple and grape and orange similar. \n",
    "\n",
    "<img src=\"embed1.png\">\n",
    "Generalize above: more complex sententce. The job of the aloggoritm is to predict juice. Given some context which was\n",
    "    last 4 words. If goal is to learn embedding, when you build a LM then natural to pick context of 4 words before. If\n",
    "    the context is 4 words on left and right we are posing a  learing problemm where you are gvien words on left and right\n",
    "    to predict. This to predict word in middle. Can also use this to predict embeddings. Or can do last 1 word. Context window\n",
    "    is like the old n-grams or n. Can cdo nearby 1 word. This simplest context of what is the nearby 1 word is a skip gram.\n",
    "    <img src=\"embed2.png\">\n",
    "    If main goal is to learn word embedding you can do simpler context vs. building a language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>word2vec</h6>\n",
    "How simple can we go? Randomly pick a context word, orange, randomly pick target word maybe juice which is 1 word after\n",
    "or 2 words before glass, or my which is before that. You pick in random in 5 or 10word window. Within +/- 10 words is\n",
    "there are a lot of choices. We want to learn word embeddings not pick the right word. So the supervised learning classification\n",
    "can get the next word wrong but we have embeddings. \n",
    "<img src=\"w2v1.png\">\n",
    "vocab size=10k; a skip gram takes a context word at random then randomly picks a context word to predict in a window size\n",
    "of +- 5/10 or some number. This random picking of a target word is a skip, where it skips some words. There are some problems. Computational\n",
    "speed, you need to compute sum of 10k words for every iteration for softmax. The deonmiator is a sum. If you have 1m hard\n",
    "to scale. One solution is to use hierarchial softmax. instead of using 10k use hierarchial softmax which scales as log(vocab_size) vs linear(vocab_size). \n",
    "in practice dont use perfectly symmetrical tree. The common words are on top where lesss common are deeper in tree. \n",
    "<img src=\"w2v2.png\">\n",
    "How do you sample context c? You can sample uniformly and you find you get more frequent words like\n",
    "tthe , a which are stop words.. orange, apple, durian not so frequent. How to get training set not dominated\n",
    "by frequently occuring words? Need less common words also. In practice P(c) not uniformly random, different \n",
    "heuristics you use to balance out to see more uncommon words. There are 2 versions of word2vec, CBOW and skip grams. CBOW uses surroundign word\n",
    "teh key problem w/skip gram is the softmax step is so expensive cause you need to calculate over entire vocabulary. \n",
    "<img src=\"w2v3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>negative sampling</h6>\n",
    "negative sampling works well also and is simpler than hierarchial softmax. Pick a context word \n",
    "and target word in a +-10 window and if it occurs 1, if not 0. orange juice is 1 and orange king is 0. To get negative samples\n",
    "pick king from dictionary at random. Assumption is if we pick random word it wont be associated w/orange. Random smaple negative words f\n",
    "from a dictionary. There are 2 steps to this process. First pick a positive example which is context/target word and give label of 1. \n",
    "Then for some number of k times take same context word and random word from dictionary and label these as negagive examples. Is ok if we pick\n",
    "random word and it appears in the context word window of +-10. Spervices learning problem k is from 5-20 for smaller and for lager datasets k is 2-5. \n",
    "\n",
    "<img src=\"ns1.png\">\n",
    "formulate this as a logistic regression problem so for logistic sigmoid you dont have sum\n",
    "in the denomiator. We have 10k logistic regression classifiers, one for each word in the vocabulary and \n",
    "when we train we are trainig 5 logistic regression classifiers, 1 for postive and 4 for negative examples where k = 4. \n",
    "<img src=\"ns2.png\">\n",
    "how do you sample to get the negative examples? one things you can do is sample in middle, according to how ofetn \n",
    "words appear. Problem is you get frequently used words. Or sample 1/vocab size which is also distorted. They found heruistic sample proportional to power of 3/4. if word\n",
    "is p(w) then raise to 3/4. \n",
    "<img src=\"ns3.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Glove</h6>\n",
    "not used as much as word2vec or skipgram models. Generate xij which is count\n",
    "of how many times a word appears next to another word in context window of say 10. \n",
    "minimize hte difference between $$Minimize the dot product between terms. Add an extra correction term f(x) to \n",
    "fix when log(0) is undefined. \n",
    "<img src=\"glove1.png\">\n",
    "<img src=\"glove2.png\">\n",
    "<img src=\"glove3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>sentiment classification</h6>\n",
    "look at piece of text to see if person likes or dislikes. with word embeddings we can build classifiers. input x is piee\n",
    "of text and y is sentiment. \n",
    "<img src=\"sent1.png\">\n",
    "look up one hot vector and look up embedding E for the wordand extract out embedding for each word. If E built from \n",
    "large corpus then you can use words even if not in training set. So you can have a smaller training set. You can \n",
    "use a sampled average, softmax classifier. You have averaging module before softmax!!Averaages teh meanings of all \n",
    "the words in example. The problem is this ignores word order!!! INstead fo summing you can use a RNN for review!\n",
    "<img src=\"sent2.png\">\n",
    "feed the embeddings into an RNN and the RNN outputs a softmax for classification. a many to one RNN architecture\n",
    "<img src=\"sent3.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>debiasing word embeddings</h6>\n",
    "how to correct word embeddings for bias. the word analogy example what if you are looking to complete \n",
    "comptuer=programer vs. woman.  You get bad examples. Bias towards to socaial economic status or gener or age, etc.. \n",
    "\n",
    "<img src=\"debias1.png\">\n",
    "points in embedding space. identify a bias direction to a particualr bias. Say gender bias. how to identyfy bias direction? \n",
    "gener, take Ehe-Eshe, Emale-Efemale, and average them to get direction for all gender related embeddings. Beutralization\n",
    "step, there are some workds that capture gender, some words we want to be gender neutral like doctor. For a word like doctor\n",
    "which should be neutral we do a projection to get rid of the bias. Project reduces the gender horizontal amount. Then \n",
    "the final step is equalization you want the difference between babysktter and grandmother to be same as between babysitteer\n",
    "and grandfaher. Several linear algebra steps. Move Grandmother and grandfathe to points which rae equidistant. There are\n",
    "many words which are gender neutral. Final detail how to decide which word to neutralize? train a classifier which ones\n",
    "are definitioal whcih are neutral. Most words are not definitial for gender. There is a small subset. Bolukbasi et al for full details\n",
    "\n",
    "<img src=\"debias2.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Seqence to Sequence basic mocels</h6>\n",
    "2 parts encoder to encode french sequnece then decoder to decode translation. Also works for image captioning in addition\n",
    "to machine translation. Take pretraomed alexnet, get rid of alexnet and feed into RNN whose job it is to generate the RNN. \n",
    "YOu can input a faature vector from the image and use it to generate a sequence of words for the catption. 3 groups who\n",
    "did this at same time. \n",
    "<img src=\"seqtoseq1.png\">\n",
    "there are some differences on how to pick the teh right translation or catpion. How to get the most likely caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Picking most likely sentence</h6>\n",
    "greedy search\n",
    "<img src=\"seqtoseq1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>beam search</h6>\n",
    "The french senctence being translated. Try to pick the first word given a beam width of 3. will consider 3 alternatives\n",
    "at a time. finds in, jane and september are the 3 highest probabilies, store in memory all 3. \n",
    "<img src=\"beam1.png\">\n",
    "the second step you pick\n",
    "the for each of the 3 choices consider what the next word is by using input and first predicted word. A pair. By rules \n",
    "of conditional probability you can break apart into 2 probabilies. For a beam width of 3 we get 3 possible firet\n",
    "word candidates, in, jane and september. Hardwire the decoder network first word to each of these 3 words and there is still \n",
    "a beam wodth of 3 you consier 30k pissobilites, for the second word. All of the 30k options and pick teh top 3. cut down\n",
    "30k back down to 3 again. so lets asay in september, jane is, jane visits is the 3 most likely candidated. if beam search decies\n",
    "it is rejecting september as a candidate. Pruning. At every step you instantiate 3 copies of the network becaure beam width\n",
    "is 3. The 3 copies can be used to evalute 30k possiblites, 10k for each softmax output. \n",
    "<img src=\"beam2.png\">\n",
    "for 3rd word you hard wire the first 2 words. then evaluate top 3 in september, jane is xxx, jane visist xxx, etc.\n",
    "the outcome of process is adding 1 word at a time will be terminated by end of sentence symbol. \n",
    "<img src=\"beam3.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>refinements to beam search</h6>\n",
    "Length normalization gives better results. We maziming a proability, probability of terms next toeach htoer can be broken\n",
    "out into seaparate individual probabilities. PRodcut of probailities. These numbers are all less than 1. Multiplying small\n",
    "numbers together results in a smaler number which can result in numerical underflow. Logs change to sum of probailities which \n",
    "is more numerically stable than multiplication of probabilities. This is strictly monotoically increasing function(Log) we know\n",
    "mazimizing should give same result as p(y!x) of u do logP(y|x) so you mazimize sum or probabilits than product for numerical\n",
    "stability. If you have long sentence then the probability of sentence is low. Objective function has undeseriable effect is it perfers\n",
    "short outputs. Short sentences have less multiplies. THe product will not be as small. This is also true for teh sum. Normalize\n",
    "by number of terms to take average this reduces penality for outputing shorter translations. Or ty to alpha where alpha is\n",
    "0.7. if alpha is o,0, ty is not being nromalized at all. compute all tentences and score them accorting to loss function\n",
    "and you pick the highesst value on normalied log objectiove. \n",
    "<img src=\"beam_refine1.png\">\n",
    "how to choose beam width b? if very large then you consider a lot of possiblities you may get better result. Small b but \n",
    "you get worse result. produciton system b=10. b=100 is large. for research systems not uncommon of 1000 or 3k. applicaiotn dependent\n",
    "<img src=\"beam_refine2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>error analysis</h6>\n",
    "ssy in dev set the human gives y* and when you run beam search you get yhat which is is a worse sentence. model has 2\n",
    "components a seq to seq encoder/decoder and beam search algorithm. \n",
    "<img src=\"beam_error1.png\">0\n",
    "How od you know if error is coming form which component? \n",
    "The rnn or beam search? always tempting to increase beam search width. might not work in making better result. \n",
    "The RNN computes P(y|x). the most useful thing is to compute P(y*|x) and P(yhat|x). Depending on which is higher\n",
    "you can figure out if BS or rnn is at fault. 2 cases. case 1 P(y*|x) > P(yhat|x). Beam search picked yhat. but y* is higher\n",
    "then yhat. SO beam search is at fault!!. case 2: P(yhat|x) > P(y*|x). We know y* is better than yhat. But RNN predicted\n",
    "    y* is less. Subtleties w/lenght normalization. Should be taking this into account. RNN is wrong. if y* is btter translation. \n",
    "<img src=\"beam_error2.png\">\n",
    "make table. which fraction error due to beam search and which from model. If most errors from BS then can increase beam witdh. If RNN\n",
    "then you can regulariztion, different network archtecture, more training data. \n",
    "<img src=\"beam_error3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>blue score</h6>\n",
    "how do you measure accuracy for translation if you have multiple translations? YOuhave a hum generated translation. \n",
    "Different humans may have slightly different translations. THE bleu score allows you to compute score how good is MT? \n",
    "as long as MT is close it will get high blue bleu score. bilingual evaluation undersstudy. \n",
    "If you have a poor MT of the word the 7 times then the old precision score would be calculated as 7/7 beacuse you\n",
    "would for each MT word see if it exists in Ref1 or Ref2 in a bow. The modified precision allows you credits only up to hte \n",
    "max number of times the word the appears in teh reference sentence. In ref1 max is 2 so the word 2 gets credit up to 2/7. Out of7 \n",
    "words you get 2 credits. Hte denominaot is the number of times in MT. The numerator is number of times max ref sentences. \n",
    "<img src=\"bleu1.png\">\n",
    "In bleu score you want to look at pairs of words not individual words. \n",
    "Count bigrams of the MT first building bigrams. Count biggrams in reference how many times bigrams appears. \n",
    "then clip the count, take the count and give credit up the max number of times the bigram appears in ref or ref2. \n",
    "clip them reducig no more it appeears at least in 1 of the references. sum of count clips/total number of bigrams. \n",
    "\n",
    "<img src=\"bleu2.png\">\n",
    "define pn as ngram version of count sum of ngrams count clip/sum count ngram. p1, p2, p3, p4. allows you to measure \n",
    "degree of which MT is similar to references. if MT is exactly same as a refernce then pn =1.0. \n",
    "<img src=\"bleu3.png\">\n",
    "we combine the pn is blue score on ngrams only. To compute 1 number you compute p1, p2, p3, p4 and do average and divide by\n",
    "4. bleu diefined by adding exp so is strictly monotonically increasing then adjust w/penalty. BP or brevity penalty. \n",
    "if you output short translations you can get good bleu score so we want longer translation so BP penallies short translation\n",
    ". is 1 if the MT outptu is longer than human reference length. \n",
    "<img src=\"bleu4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>attemtopm model intuition</h6>\n",
    "we have been usig RNN encoer then RNN decoder. Modification using attention to mske this owrk better. Long french sentence\n",
    "ask long encoder to store in activations. THe decoder network generate translation. human translator doesnt work like RNN, human \n",
    "would read first part generate translation then look at parts and translate sectiosn. Encoder/decoder works well for short\n",
    "sentences but for longer than 30 words the performance comes down. The bleu scores come down. The green line is attn. \n",
    "Attention model. Short sentence.  \n",
    "<img src=\"attn1.png\">\n",
    "when looking at first word where do you look in french? not at end of sentence. there are a set of attention weights\n",
    "that tell you where to look. so mimics human where you look at parts of sententce and translate parts of it. for first step\n",
    "hidden state S1 and set of attention weights alpha(1,1), alpha(1,2). alpha(1,3) where 11 tells you how much you pay attentionto first\n",
    "word. For second word second set of weights. how do you determine context, c and how to calculate alpha? every step threre\n",
    "are attention weights. \n",
    "<img src=\"attn2.png\">\n",
    "at prime forward and reverse represent feature vector for time step t for attention. tprime used to index into words\n",
    "into french sentence. State S to generate translation with context c, previous state S0 and output y1. teh alpha parametres \n",
    "are used to make c context. the context is a weighted sum of the different time steps. Sum of alpha(1,tprime) os 1. This sum for each \n",
    "context step. \n",
    "<img src=\"attn3.png\">\n",
    "how to compute attention weights, a(t,tprime) is amouont of attentions. Runs in quadraic time tx,ty. are lengths of stentence but shince \n",
    "they arent so long it may not matter. \n",
    "<img src=\"attn4.png\">\n",
    "<img src=\"attn5.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>speech</h6>\n",
    "3000h on audio typical. best commercial systems trained on 10k or 100k hours of audio. used to suse phoenemes, now w/end to end\n",
    "deep learning done use them anymore. how to build speech recognition system? time frames transcribe, use CTC cost. deeoer model\n",
    "bidirectional GRP or bidirectional LSTM. NNwith equal number of inputs/outputs seq to seq RNN. Number of time steps are \n",
    "large. Usually input sizes are much larger than output. \n",
    "100hz sampling at 10s = 1000 samples and the output may not have 1000 alphabets. Teh ctc allows you to fix this. ttt_h_eee___space\n",
    "this sequence is the currect output of the first sound \"the q\" collapse characters not separated by blank. There is a space\n",
    "between the and quick. By collapsing repeated characters. allows NN to have 1k outputs!!! 19 char for the quick brown fox but if you\n",
    "need 1k outptus you can pad 19 up to 1k w/the repeat part. \n",
    "<img src=\"speech1.png\">\n",
    "<h6>trigger word</h6>\n",
    "if you output 1 when there is a trigger word then the problem is the outptu is mostly 0. You can amke the output 1\n",
    "for a couple time steps. Hack. you want RNN to output 1 when you detect a trigger word. \n",
    "\n",
    "<img src=\"trigger1.png\">\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"trigger2.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
